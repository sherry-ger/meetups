{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Mistral to extract keywords from a passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "comment = \"Me and two friends stayed for four and a half months. It was a great place to stay!  The apartment was very comfortable and I really enjoyed having the park with running path across the street. The only downside was it was not within walking distance to restaurants.\"\n",
    "response = ollama.chat(model='mistral', messages=[\n",
    "   {\n",
    "     'role': 'user',\n",
    "     'content': 'Can you extract keywords and phrases from this passage and put them into a comma separated list: ' + comment,\n",
    "     'stream': False\n",
    "   },\n",
    " ])\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract keywords from Airbnb users reviews using Mistral and output them to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ollama\n",
    "import time\n",
    "\n",
    "df_reviews = pd.read_json('/Data/Airbnb/LA_Dec_2023/reviews-20240216.ndjson', lines=True)\n",
    "print(df_reviews.columns) # what columns\n",
    "print(df_reviews.shape)   # num of rows, columns\n",
    "print(df_reviews.iloc[11]['comments']) # for example\n",
    "\n",
    "def extractKeyPhrases(comments):\n",
    "    print(\"comment is: \" + comments)\n",
    "    response = ollama.generate(\n",
    "        model='mistral', \n",
    "        prompt='Can you extract keywords and phrases from a passage and put them into a comma separated list only, without any additional header information. \\\n",
    "            Please do not add sentences like here is a list. \\\n",
    "            Also, please omit names of people like Hank or Chas or Maianna. Here is the passage.' + comments, \n",
    "        stream=False)\n",
    "    print(\"response: \" + response['response'])\n",
    "    return(response['response'])\n",
    "\n",
    "file = open(\"keyphrases.txt\", \"w\")\n",
    "for index, row in df_reviews.iterrows():\n",
    "    if(index > 0):\n",
    "      comments = row['comments']\n",
    "      phrases = extractKeyPhrases(comments)\n",
    "      file.write(phrases+\"\\n\")\n",
    "      time.sleep(5)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'instance-0000000005',\n",
       " 'cluster_name': 'ae84f52516e54cba9da869c3846ca0c6',\n",
       " 'cluster_uuid': 'vZednNOIQT-ZJpZKbFq2eA',\n",
       " 'version': {'number': '8.12.2',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': '48a287ab9497e852de30327444b0809e55d46466',\n",
       "  'build_date': '2024-02-19T10:04:32.774273190Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '9.9.2',\n",
       "  'minimum_wire_compatibility_version': '7.17.0',\n",
       "  'minimum_index_compatibility_version': '7.0.0'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "es_cloud_id = getpass.getpass(\"Enter Cloud ID\")\n",
    "es_pwd = getpass.getpass(\"Enter Cloud password\")\n",
    "\n",
    "\n",
    "# Initialize the Elasticsearch client\n",
    "es = Elasticsearch(\n",
    "    cloud_id=es_cloud_id,\n",
    "    basic_auth=(\"elastic\", es_pwd),\n",
    "    request_timeout=600\n",
    ")\n",
    "es.info().body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest extracted keywords into Elasticsearch for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/Data/Airbnb/LA_Dec_2023/keyphrases.txt', 'r')\n",
    "Lines = file.readlines()\n",
    "\n",
    "def generator():\n",
    "  count = 0\n",
    "  for line in Lines:\n",
    "    count += 1\n",
    "    line = line.strip()\n",
    "    if(len(line) > 0):\n",
    "      if(line.find(':')!= -1):\n",
    "        line = line.split(':', 1)[1]\n",
    "   \n",
    "      # print(clean_string)\n",
    "      phrases = line.split(',')\n",
    "\n",
    "      for phrase in phrases:\n",
    "        phrase = phrase.strip()\n",
    "        yield {\n",
    "          \"_index\": \"extracted_key_phrases\",\n",
    "          \"phrase\": phrase\n",
    "        }\n",
    "        \n",
    "file.close\n",
    "\n",
    "try:\n",
    "  res = bulk(es, generator())\n",
    "  print(\"Response: \", res)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest Airbnb listings and tag them with the extract keywords using a zero shot classifiction model.\n",
    "\n",
    "Ingest listings and tag them with extracted keywords using zero shot classification. The model we are using is `typeform__distilbert-base-uncased-mnli`.\n",
    "\n",
    "The follow section loads the model into Elasticsearch using [eland](https://github.com/elastic/eland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eland.ml.pytorch import PyTorchModel\n",
    "from eland.ml.pytorch.transformers import TransformerModel\n",
    "\n",
    "import logging\n",
    "import tempfile\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "MODEL_HUB_URL = \"https://huggingface.co\"\n",
    "\n",
    "def load_model(model_id, task_type):\n",
    "  with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "    logger.info(f\"Loading HuggingFace transformer tokenizer and model [{model_id}] for task [{task_type}]\" )\n",
    "\n",
    "    tm = TransformerModel(model_id=model_id, task_type=task_type)\n",
    "    model_path, config, vocab_path = tm.save(tmp_dir)\n",
    "\n",
    "    ptm = PyTorchModel(es, tm.elasticsearch_model_id())\n",
    "    model_exists = es.options(ignore_status=404).ml.get_trained_models(model_id=ptm.model_id).meta.status == 200\n",
    "\n",
    "    if model_exists:\n",
    "      logger.info(\"Model has already been imported\")\n",
    "    else:\n",
    "      logger.info(\"Importing model\")\n",
    "      ptm.import_model(model_path=model_path, config_path=None, vocab_path=vocab_path, config=config)\n",
    "      logger.info(\"Starting model deployment\")\n",
    "      ptm.start()\n",
    "      logger.info(f\"Model successfully imported with id '{ptm.model_id}'\")\n",
    "load_model(\"typeform/distilbert-base-uncased-mnli\", \"zero_shot_classification\")\n",
    "\n",
    "# fetch it so we can see how it loaded\n",
    "es.ml.get_trained_models(model_id=\"typeform__distilbert-base-uncased-mnli\").body\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest listings using ingest pipeline into Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_listings = pd.read_json('/Users/sherryger/Documents/Data/Airbnb/LA_Dec_2023/listings-small-20240216.ndjson', lines=True)\n",
    "df_listings = df_listings.dropna()  # drop null value rows\n",
    "\n",
    "def generator():\n",
    "    for index, row in df_listings.iterrows():\n",
    "        if(index > 0):\n",
    "          if(len(row[\"neighborhood_overview\"]) > 0):\n",
    "            price = row['price']\n",
    "            price = price.replace('$', '').replace(',', '')\n",
    "            new_price = float(price)\n",
    "            \n",
    "            yield {\n",
    "              \"_index\": \"airbnb_listings_zero_shot\",\n",
    "              \"pipeline\": \"airbnb-reviews-zero-class\",\n",
    "              \"review_scores_communication\": row[\"review_scores_communication\"],\n",
    "              \"scrape_id\": row[\"scrape_id\"],\n",
    "              \"picture_url\": row[\"picture_url\"],\n",
    "              \"number_of_reviews_l30d\": row[\"number_of_reviews_l30d\"],\n",
    "              \"source\": row[\"source\"],\n",
    "              \"host_since\": row[\"host_since\"],\n",
    "              \"availability_365\": row[\"availability_365\"],\n",
    "              \"number_of_reviews_ltm\": row[\"number_of_reviews_ltm\"],\n",
    "              \"first_review\": row[\"first_review\"],\n",
    "              \"calculated_host_listings_count_shared_rooms\": row[\"calculated_host_listings_count_shared_rooms\"],\n",
    "              \"description\": row[\"description\"],\n",
    "              \"bathrooms\": row[\"bathrooms\"],\n",
    "              \"bathrooms_text\": row[\"bathrooms_text\"],\n",
    "              \"maximum_maximum_nights\": row[\"maximum_maximum_nights\"],\n",
    "              \"availability_90\": row[\"availability_90\"],\n",
    "              \"host_about\": row[\"host_about\"],\n",
    "              \"room_type\": row[\"room_type\"],\n",
    "              \"last_scraped\": row[\"last_scraped\"],\n",
    "              \"property_type\": row[\"property_type\"],\n",
    "              \"beds\": row[\"beds\"],\n",
    "              \"maximum_minimum_nights\": row[\"maximum_minimum_nights\"],\n",
    "              \"calculated_host_listings_count_private_rooms\": row[\"calculated_host_listings_count_private_rooms\"],\n",
    "              \"calculated_host_listings_count\": row[\"calculated_host_listings_count\"],\n",
    "              \"name\": row[\"name\"],\n",
    "              \"host_listings_count\": row[\"host_listings_count\"],\n",
    "              \"maximum_nights_avg_ntm\": row[\"maximum_nights_avg_ntm\"],\n",
    "              \"license\": row[\"license\"],\n",
    "              \"neighbourhood\": row[\"neighbourhood\"],\n",
    "              \"price\": new_price,\n",
    "              \"has_availability\": row[\"has_availability\"],\n",
    "              \"review_scores_rating\": row[\"review_scores_rating\"],\n",
    "              \"review_scores_location\": row[\"review_scores_location\"],\n",
    "              \"host_response_time\": row[\"host_response_time\"],\n",
    "              \"host_is_superhost\": row[\"host_is_superhost\"],\n",
    "              \"host_neighbourhood\": row[\"host_neighbourhood\"],\n",
    "              \"neighbourhood_cleansed\": row[\"neighbourhood_cleansed\"],\n",
    "              \"listing_url\": row[\"listing_url\"],\n",
    "              \"host_has_profile_pic\": row[\"host_has_profile_pic\"],\n",
    "              \"review_scores_accuracy\": row[\"review_scores_accuracy\"],\n",
    "              \"host_location\": row[\"host_location\"],\n",
    "              \"listing_location\": {\"lat\": float(row[\"latitude\"]), \"lon\": float(row[\"longitude\"])},\n",
    "              \"neighborhood_overview\": row[\"neighborhood_overview\"],\n",
    "              \"host_picture_url\": row[\"host_picture_url\"],\n",
    "              \"host_total_listings_count\": row[\"host_total_listings_count\"],\n",
    "              \"review_scores_checkin\": row[\"review_scores_checkin\"],\n",
    "              \"host_response_rate\": row[\"host_response_rate\"].strip('%'),\n",
    "              \"host_url\": row[\"host_url\"],\n",
    "              \"neighbourhood_group_cleansed\": row[\"neighbourhood_group_cleansed\"],\n",
    "              \"bedrooms\": row[\"bedrooms\"],\n",
    "              \"maximum_nights\": row[\"maximum_nights\"],\n",
    "              \"availability_60\": row[\"availability_60\"],\n",
    "              \"calculated_host_listings_count_entire_homes\": row[\"calculated_host_listings_count_entire_homes\"],\n",
    "              \"reviews_per_month\": row[\"reviews_per_month\"],\n",
    "              \"host_id\": row[\"host_id\"],\n",
    "              \"host_name\": row[\"host_name\"],\n",
    "              \"accommodates\": row[\"accommodates\"],\n",
    "              \"availability_30\": row[\"availability_30\"],\n",
    "              \"instant_bookable\": row[\"instant_bookable\"],\n",
    "              \"minimum_nights\": row[\"minimum_nights\"],\n",
    "              \"calendar_updated\": row[\"calendar_updated\"],\n",
    "              \"calendar_last_scraped\": row[\"calendar_last_scraped\"],\n",
    "              \"number_of_reviews\": row[\"number_of_reviews\"],\n",
    "              \"last_review\": row[\"last_review\"],\n",
    "              \"review_scores_value\": row[\"review_scores_value\"],\n",
    "              \"host_acceptance_rate\": row[\"host_acceptance_rate\"],\n",
    "              \"host_thumbnail_url\": row[\"host_thumbnail_url\"],\n",
    "              \"host_identity_verified\": row[\"host_identity_verified\"],\n",
    "              \"amenities\": row[\"amenities\"],\n",
    "              \"minimum_nights_avg_ntm\": row[\"minimum_nights_avg_ntm\"],\n",
    "              \"review_scores_cleanliness\": row[\"review_scores_cleanliness\"],\n",
    "              \"id\": row[\"id\"],\n",
    "              \"host_verifications\": row[\"host_verifications\"],\n",
    "              \"minimum_minimum_nights\": row[\"minimum_minimum_nights\"],\n",
    "              \"minimum_maximum_nights\": row[\"minimum_maximum_nights\"]\n",
    "            }\n",
    "\n",
    "try:\n",
    "    res = bulk(es, generator())\n",
    "    print(\"Response: \", res)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying using BM25 with the Mistral extracted keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query={\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "      {\n",
    "          \"range\": {\n",
    "            \"review_scores_cleanliness\": {\n",
    "              \"gte\": 4.5\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "      \"filter\": [\n",
    "        {\n",
    "          \"range\": {\n",
    "            \"comfortable\": {\n",
    "              \"gte\": 0.7\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"range\": {\n",
    "            \"entertainment\": {\n",
    "              \"gte\": 0.7\n",
    "            }\n",
    "          } \n",
    "        },\n",
    "        {\n",
    "          \"range\": {\n",
    "            \"walking distance\": {\n",
    "              \"gte\": 0.7\n",
    "            }\n",
    "          } \n",
    "        }\n",
    "      ],\n",
    "      \"should\": [\n",
    "        {\n",
    "          \"match\": {\n",
    "            \"neighborhood_overview\": \"beach\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "\n",
    "resp = es.search(index=\"airbnb_listings_elser\", query=query, size=5,\n",
    "  _source=[\"review_scores_cleanliness\", \"comfortable\", \"walking distance\", \"entertainment\", \"neighborhood_overview\"]\n",
    ")\n",
    "\n",
    "for hit in resp['hits']['hits']:\n",
    "    score = hit['_score']\n",
    "    overview = hit['_source']['neighborhood_overview']\n",
    "    walking_distance = hit['_source']['walking distance']\n",
    "    cleanliness_score = hit['_source']['review_scores_cleanliness']\n",
    "    comfort_score = hit['_source']['comfortable']\n",
    "    entertainment_score = hit['_source']['entertainment']\n",
    "    print(f\"Overview: {overview}\\nWalking Distance: {walking_distance}\\nCleanlinesse: {cleanliness_score}\\nComfort: {comfort_score}\\nEntertainment: {entertainment_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search with ELSER\n",
    "\n",
    "In Elasticsearch, we converted the neighborhood description into sparse vector so we can perform semantic search. ELSER is a language model based on the BERT model. It is a model that is designed to work with out of domain corpus. The follow section demonstrate semantic search on the neighborhood description field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = input(\"Enter a question :\")\n",
    "print('\\n')\n",
    "\n",
    "query={\n",
    "  \"text_expansion\": {\n",
    "    \"neighborhood_overview_embedding\": {\n",
    "      \"model_id\": \".elser_model_2\",\n",
    "      \"model_text\": query_text\n",
    "    }\n",
    "  }\n",
    "}\n",
    "resp = es.search(index=\"airbnb_listings_elser\", query=query, size=5,\n",
    "  _source=[\"review_scores_cleanliness\", \"comfortable\", \"walking distance\", \"entertainment\", \"neighborhood_overview\"]\n",
    ")\n",
    "\n",
    "for hit in resp['hits']['hits']:\n",
    "    score = hit['_score']\n",
    "    overview = hit['_source']['neighborhood_overview']\n",
    "    walking_distance = hit['_source']['walking distance']\n",
    "    cleanliness_score = hit['_source']['review_scores_cleanliness']\n",
    "    comfort_score = hit['_source']['comfortable']\n",
    "    entertainment_score = hit['_source']['entertainment']\n",
    "    print(f\"Overview: {overview}\\nWalking Distance: {walking_distance}\\nCleanlinesse: {cleanliness_score}\\nComfort: {comfort_score}\\nEntertainment:  {entertainment_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining BM25 and Semantic search for more relevant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = input(\"Enter a question :\")\n",
    "print('\\n')\n",
    "\n",
    "query={\n",
    "  \"bool\": {\n",
    "      \"should\": [\n",
    "        {\n",
    "          \"text_expansion\": {\n",
    "            \"neighborhood_overview_embedding\": {\n",
    "              \"model_id\": \".elser_model_2\",\n",
    "              \"model_text\": query_text\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"bool\": {\n",
    "            \"must\": [\n",
    "              {\n",
    "                \"range\": {\n",
    "                  \"review_scores_cleanliness\": {\n",
    "                    \"gte\": 4.5\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            ],\n",
    "            \"filter\": [\n",
    "              {\n",
    "                \"range\": {\n",
    "                  \"comfortable\": {\n",
    "                    \"gte\": 0.7\n",
    "                  }\n",
    "                }\n",
    "              },\n",
    "              {\n",
    "                \"range\": {\n",
    "                  \"entertainment\": {\n",
    "                    \"gte\": 0.7\n",
    "                  }\n",
    "                }\n",
    "              },\n",
    "              {\n",
    "                \"range\": {\n",
    "                  \"walking distance\": {\n",
    "                    \"gte\": 0.7\n",
    "                  }\n",
    "                }\n",
    "              },\n",
    "              {\n",
    "                \"geo_distance\": {\n",
    "                  \"distance\": \"200m\",\n",
    "                  \"listing_location\": {\n",
    "                    \"lat\": 34.02,\n",
    "                    \"lon\": -118.52\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "\n",
    "resp = es.search(index=\"airbnb_listings_elser\", query=query, size=5,\n",
    "  _source=[\"review_scores_cleanliness\", \"comfortable\", \"walking distance\", \"entertainment\", \"neighborhood_overview\", \"listing_location\"]\n",
    ")\n",
    "\n",
    "for hit in resp['hits']['hits']:\n",
    "    score = hit['_score']\n",
    "    overview = hit['_source']['neighborhood_overview']\n",
    "    walking_distance = hit['_source']['walking distance']\n",
    "    cleanliness_score = hit['_source']['review_scores_cleanliness']\n",
    "    comfort_score = hit['_source']['comfortable']\n",
    "    entertainment_score = hit['_source']['entertainment']\n",
    "    listing_location = hit['_source']['listing_location']\n",
    "    print(f\"Overview: {overview}\\nWalking Distance: {walking_distance}\\nLocation: {listing_location}\\nCleanlinesse: {cleanliness_score}\\nComfort: {comfort_score}\\nEntertainment: {entertainment_score}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
